Sentence 01 : ['0.312', '0.149', '0.000']['0.375', '0.163', '0.000']['0.438', '0.176', '0.000']['0.438', '0.176', '0.000']
Sentence 02 : ['0.444', '0.250', '0.000']['0.444', '0.250', '0.000']['0.444', '0.250', '0.000']['0.444', '0.250', '0.000']
Sentence 03 : ['0.538', '0.312', '0.000']['0.538', '0.312', '0.000']['0.538', '0.312', '0.000']['0.615', '0.333', '0.000']
Sentence 04 : ['0.357', '0.172', '0.000']['0.500', '0.204', '0.000']['0.500', '0.204', '0.000']['0.500', '0.204', '0.000']
Sentence 05 : ['0.308', '0.167', '0.000']['0.385', '0.186', '0.000']['0.385', '0.186', '0.000']['0.462', '0.204', '0.000']
Sentence 06 : ['0.600', '0.471', '0.413']['0.600', '0.471', '0.413']['0.600', '0.471', '0.413']['0.600', '0.471', '0.413']
Sentence 07 : ['0.308', '0.167', '0.000']['0.462', '0.204', '0.000']['0.385', '0.186', '0.000']['0.462', '0.204', '0.000']
Sentence 08 : ['0.500', '0.404', '0.000']['0.625', '0.553', '0.411']['0.625', '0.553', '0.411']['0.625', '0.553', '0.411']
Sentence 09 : ['0.372', '0.000', '0.000']['0.372', '0.000', '0.000']['0.372', '0.000', '0.000']['0.372', '0.000', '0.000']
Sentence 10 : ['0.300', '0.000', '0.000']['0.600', '0.385', '0.000']['0.500', '0.351', '0.000']['0.500', '0.248', '0.000']
Sentence 11 : ['0.538', '0.382', '0.251']['0.615', '0.408', '0.262']['0.615', '0.408', '0.262']['0.615', '0.408', '0.262']
Sentence 12 : ['0.385', '0.264', '0.000']['0.462', '0.289', '0.000']['0.385', '0.264', '0.000']['0.462', '0.289', '0.000']
Sentence 13 : ['0.444', '0.250', '0.000']['0.556', '0.280', '0.000']['0.556', '0.280', '0.000']['0.556', '0.280', '0.000']
Sentence 14 : ['0.500', '0.306', '0.188']['0.500', '0.306', '0.188']['0.500', '0.306', '0.188']['0.500', '0.306', '0.188']
Sentence 15 : ['0.396', '0.303', '0.204']['0.528', '0.350', '0.225']['0.528', '0.350', '0.225']['0.462', '0.327', '0.215']
Sentence 16 : ['0.383', '0.264', '0.000']['0.383', '0.264', '0.000']['0.460', '0.355', '0.241']['0.460', '0.355', '0.241']
Sentence 17 : ['0.444', '0.354', '0.286']['0.444', '0.354', '0.286']['0.444', '0.354', '0.286']['0.444', '0.354', '0.286']
Sentence 18 : ['0.399', '0.258', '0.000']['0.499', '0.333', '0.000']['0.499', '0.333', '0.000']['0.549', '0.350', '0.000']
Sentence 19 : ['0.333', '0.182', '0.000']['0.250', '0.157', '0.000']['0.333', '0.257', '0.200']['0.333', '0.257', '0.200']
Sentence 20 : ['0.543', '0.348', '0.000']['0.633', '0.461', '0.312']['0.543', '0.348', '0.000']['0.543', '0.348', '0.000']
Sentence 21 : ['0.625', '0.452', '0.000']['0.750', '0.606', '0.437']['0.750', '0.606', '0.437']['0.750', '0.606', '0.437']
Sentence 22 : ['0.600', '0.471', '0.000']['0.900', '0.745', '0.560']['0.800', '0.629', '0.397']['0.800', '0.629', '0.397']
Sentence 23 : ['0.500', '0.353', '0.230']['0.500', '0.353', '0.230']['0.500', '0.353', '0.230']['0.500', '0.353', '0.230']
Sentence 24 : ['0.471', '0.306', '0.192']['0.529', '0.325', '0.200']['0.529', '0.325', '0.200']['0.471', '0.306', '0.192']
Sentence 25 : ['0.375', '0.000', '0.000']['0.375', '0.247', '0.000']['0.375', '0.247', '0.000']['0.375', '0.247', '0.000']

The BLEU score for each test sentence is reported in the order of with 1K, 10K, 15K and 30K data trained alignment models.
Inside each bracket, the three BLEU scores are for n = 1,2,3.

From the result above, we can find that, generally, as the larger size of the data for the alignment model, the better result (higher BLEU) it is.
This is common for most training problems since the larger size of the data helps to characterize the model better.
Also, for the same alignment model, the BLEU score for n = 1 is higher than n = 2, and later is higher than n = 3.
This is also easy for understanding since it is easier for matching the unigram (n = 1) than the bigram and trigram (n = 2,3)